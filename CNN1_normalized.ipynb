{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aada3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyedflib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ê³ ì • ì„¤ì •\n",
    "sampling_rate = 256\n",
    "segment_length = 30 * sampling_rate\n",
    "label_map = {\n",
    "    'Sleep stage W': 0,\n",
    "    'Sleep stage N1': 1,\n",
    "    'Sleep stage N2': 1,\n",
    "    'Sleep stage N3': 2,\n",
    "    'Sleep stage R': 3\n",
    "}\n",
    "root_dir = \"/home/mhb0917/ìº¡ìŠ¤í†¤ë””ìì¸/sleep/recordings\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce987686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_sn(sn_list):\n",
    "    all_segments = []\n",
    "    all_labels = []\n",
    "\n",
    "    for sn in sn_list:\n",
    "        base = f\"SN{sn:03d}\"\n",
    "        ecg_path = os.path.join(root_dir, f\"{base}.edf\")\n",
    "        label_path = os.path.join(root_dir, f\"{base}_sleepscoring.edf\")\n",
    "\n",
    "        if not os.path.exists(ecg_path) or not os.path.exists(label_path):\n",
    "            print(f\"âŒ íŒŒì¼ ì—†ìŒ: {base}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ecg_reader = pyedflib.EdfReader(ecg_path)\n",
    "            ecg_signal = ecg_reader.readSignal(7)\n",
    "        finally:\n",
    "            ecg_reader._close()\n",
    "\n",
    "        try:\n",
    "            label_reader = pyedflib.EdfReader(label_path)\n",
    "            annotations = label_reader.readAnnotations()\n",
    "        finally:\n",
    "            label_reader._close()\n",
    "\n",
    "        onsets, durations, labels = annotations\n",
    "        label_seq = []\n",
    "        for i in range(len(labels)):\n",
    "            label_str = labels[i].decode() if isinstance(labels[i], bytes) else labels[i]\n",
    "            if label_str in label_map:\n",
    "                label_index = label_map[label_str]\n",
    "                num_segments = int(durations[i] // 30)\n",
    "                label_seq.extend([label_index] * num_segments)\n",
    "\n",
    "        max_segments = len(ecg_signal) // segment_length\n",
    "        num_segments = min(len(label_seq), max_segments)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start = i * segment_length\n",
    "            end = start + segment_length\n",
    "            segment = ecg_signal[start:end]\n",
    "\n",
    "            # âœ… ECG ì •ê·œí™” (Z-score ë°©ì‹)\n",
    "            segment = (segment - np.mean(segment)) / (np.std(segment) + 1e-6)\n",
    "\n",
    "            all_segments.append(segment)\n",
    "            all_labels.append(label_seq[i])\n",
    "\n",
    "    X = torch.tensor(np.array(all_segments), dtype=torch.float32).unsqueeze(1)\n",
    "    y = torch.tensor(all_labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ec1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_balanced_data_from_sn(sn_list):\n",
    "    all_segments = []\n",
    "    all_labels = []\n",
    "\n",
    "    for sn in sn_list:\n",
    "        try:\n",
    "            X, y = load_data_from_sn([sn])  # SN í•˜ë‚˜ë§Œ ë¶ˆëŸ¬ì˜´\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SN{sn:03d} ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "        if len(y) == 0:\n",
    "            print(f\"âš ï¸ SN{sn:03d}: ë¼ë²¨ ì—†ìŒ â†’ ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "\n",
    "        y_np = y.numpy()\n",
    "        X_np = X.numpy()\n",
    "\n",
    "        label_counts = Counter(y_np)\n",
    "        if len(label_counts) < 2:\n",
    "            print(f\"âš ï¸ SN{sn:03d}: ë¼ë²¨ ë‹¤ì–‘ì„± ë¶€ì¡± â†’ ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "\n",
    "        min_count = min(label_counts.values())\n",
    "        indices = []\n",
    "\n",
    "        for label in sorted(label_counts.keys()):\n",
    "            label_indices = np.where(y_np == label)[0]\n",
    "            if len(label_indices) < min_count:\n",
    "                continue\n",
    "            sampled = np.random.choice(label_indices, min_count, replace=False)\n",
    "            indices.extend(sampled)\n",
    "\n",
    "        if not indices:\n",
    "            print(f\"âš ï¸ SN{sn:03d}: ìœ íš¨í•œ ìƒ˜í”Œ ì—†ìŒ â†’ ê±´ë„ˆëœ€\")\n",
    "            continue\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "        all_segments.append(X_np[indices])\n",
    "        all_labels.append(y_np[indices])\n",
    "\n",
    "        print(f\"âœ… SN{sn:03d} ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ {min_count}ê°œ\")\n",
    "\n",
    "    if not all_segments:\n",
    "        raise ValueError(\"âš ï¸ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. SN ëª©ë¡ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "    X_all = torch.tensor(np.concatenate(all_segments), dtype=torch.float32)\n",
    "    y_all = torch.tensor(np.concatenate(all_labels), dtype=torch.long)\n",
    "    return X_all, y_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fee5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SN001 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 23ê°œ\n",
      "âœ… SN002 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 82ê°œ\n",
      "âœ… SN003 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 150ê°œ\n",
      "âœ… SN004 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 64ê°œ\n",
      "âœ… SN005 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 127ê°œ\n",
      "âœ… SN006 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 65ê°œ\n",
      "âœ… SN007 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 67ê°œ\n",
      "âœ… SN008 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 39ê°œ\n",
      "âœ… SN009 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 91ê°œ\n",
      "âœ… SN010 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 101ê°œ\n",
      "âœ… SN011 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 37ê°œ\n",
      "âœ… SN012 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 184ê°œ\n",
      "âœ… SN013 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 65ê°œ\n",
      "âŒ íŒŒì¼ ì—†ìŒ: SN014\n",
      "âš ï¸ SN014: ë¼ë²¨ ì—†ìŒ â†’ ê±´ë„ˆëœ€\n",
      "âœ… SN015 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 102ê°œ\n",
      "âœ… SN016 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 24ê°œ\n",
      "âœ… SN017 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 96ê°œ\n",
      "âœ… SN018 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 19ê°œ\n",
      "âœ… SN019 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 72ê°œ\n",
      "âœ… SN020 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 67ê°œ\n",
      "âœ… SN021 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 156ê°œ\n",
      "âœ… SN022 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 115ê°œ\n",
      "âœ… SN023 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 74ê°œ\n",
      "âœ… SN024 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 70ê°œ\n",
      "âœ… SN025 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 106ê°œ\n",
      "âœ… SN026 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 127ê°œ\n",
      "âœ… SN027 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 19ê°œ\n",
      "âœ… SN028 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 136ê°œ\n",
      "âœ… SN029 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 59ê°œ\n",
      "âœ… SN030 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 108ê°œ\n",
      "âœ… SN031 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 74ê°œ\n",
      "âœ… SN032 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 133ê°œ\n",
      "âœ… SN033 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 47ê°œ\n",
      "âœ… SN034 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 75ê°œ\n",
      "âœ… SN035 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 108ê°œ\n",
      "âœ… SN036 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 87ê°œ\n",
      "âœ… SN037 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 65ê°œ\n",
      "âœ… SN038 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 61ê°œ\n",
      "âœ… SN039 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 108ê°œ\n",
      "âœ… SN040 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 62ê°œ\n",
      "âœ… SN041 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 130ê°œ\n",
      "âœ… SN042 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 148ê°œ\n",
      "âœ… SN043 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 56ê°œ\n",
      "âœ… SN044 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 55ê°œ\n",
      "âœ… SN045 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 129ê°œ\n",
      "âœ… SN046 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 49ê°œ\n",
      "âœ… SN047 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 125ê°œ\n",
      "âœ… SN048 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 146ê°œ\n",
      "âœ… SN049 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 41ê°œ\n",
      "âœ… SN050 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 25ê°œ\n",
      "âœ… SN051 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 84ê°œ\n",
      "âœ… SN052 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 59ê°œ\n",
      "âœ… SN053 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 163ê°œ\n",
      "âœ… SN054 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 28ê°œ\n",
      "âœ… SN055 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 115ê°œ\n",
      "âœ… SN056 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 64ê°œ\n",
      "âœ… SN057 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 7ê°œ\n",
      "âœ… SN058 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 103ê°œ\n",
      "âœ… SN059 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 138ê°œ\n",
      "âœ… SN060 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 46ê°œ\n",
      "âœ… SN061 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 150ê°œ\n",
      "âœ… SN062 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 5ê°œ\n",
      "âœ… SN063 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 139ê°œ\n",
      "âŒ íŒŒì¼ ì—†ìŒ: SN064\n",
      "âš ï¸ SN064: ë¼ë²¨ ì—†ìŒ â†’ ê±´ë„ˆëœ€\n",
      "âœ… SN065 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 65ê°œ\n",
      "âœ… SN066 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 88ê°œ\n",
      "âœ… SN067 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 123ê°œ\n",
      "âœ… SN068 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 116ê°œ\n",
      "âœ… SN069 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 69ê°œ\n",
      "âœ… SN070 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 35ê°œ\n",
      "âœ… SN071 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 16ê°œ\n",
      "âœ… SN072 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 115ê°œ\n",
      "âœ… SN073 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 39ê°œ\n",
      "âœ… SN074 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 37ê°œ\n",
      "âœ… SN075 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 186ê°œ\n",
      "âœ… SN076 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 56ê°œ\n",
      "âœ… SN077 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 85ê°œ\n",
      "âœ… SN078 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 55ê°œ\n",
      "âœ… SN079 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 61ê°œ\n",
      "âœ… SN080 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 28ê°œ\n",
      "âœ… SN081 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 2ê°œ\n",
      "âœ… SN082 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 37ê°œ\n",
      "âœ… SN083 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 136ê°œ\n",
      "âœ… SN084 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 27ê°œ\n",
      "âœ… SN085 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 111ê°œ\n",
      "âœ… SN086 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 110ê°œ\n",
      "âœ… SN087 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 34ê°œ\n",
      "âœ… SN088 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 125ê°œ\n",
      "âœ… SN089 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 85ê°œ\n",
      "âœ… SN090 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 76ê°œ\n",
      "âœ… SN091 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 40ê°œ\n",
      "âœ… SN092 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 93ê°œ\n",
      "âœ… SN093 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 71ê°œ\n",
      "âœ… SN094 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 79ê°œ\n",
      "âœ… SN095 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 50ê°œ\n",
      "âœ… SN096 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 55ê°œ\n",
      "âœ… SN097 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 46ê°œ\n",
      "âœ… SN098 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 80ê°œ\n",
      "âœ… SN099 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 56ê°œ\n",
      "âœ… SN100 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 81ê°œ\n",
      "âœ… SN101 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 120ê°œ\n",
      "âœ… SN102 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 36ê°œ\n",
      "âœ… SN103 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 70ê°œ\n",
      "âœ… SN104 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 104ê°œ\n",
      "âœ… SN105 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 34ê°œ\n",
      "âœ… SN106 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 53ê°œ\n",
      "âœ… SN107 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 77ê°œ\n",
      "âœ… SN108 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 50ê°œ\n",
      "âœ… SN109 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 48ê°œ\n",
      "âœ… SN110 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 96ê°œ\n",
      "âœ… SN111 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 135ê°œ\n",
      "âœ… SN112 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 83ê°œ\n",
      "âœ… SN113 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 85ê°œ\n",
      "âœ… SN114 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 73ê°œ\n",
      "âœ… SN115 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 98ê°œ\n",
      "âœ… SN116 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 43ê°œ\n",
      "âœ… SN117 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 108ê°œ\n",
      "âœ… SN118 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 114ê°œ\n",
      "âœ… SN119 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 89ê°œ\n",
      "âœ… SN120 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 29ê°œ\n",
      "âœ… SN121 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 61ê°œ\n",
      "âœ… SN122 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 66ê°œ\n",
      "âœ… SN123 ì²˜ë¦¬ ì™„ë£Œ: í´ë˜ìŠ¤ë‹¹ 98ê°œ\n",
      "âŒ íŒŒì¼ ì—†ìŒ: SN135\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_balanced_data_from_sn(list(range(1, 94)))  # SN001 ~ SN093\n",
    "X_val, y_val = load_balanced_data_from_sn(list(range(94, 124)))   # SN094 ~ SN123\n",
    "X_test, y_test = load_data_from_sn(list(range(124, 154)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90d79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# ğŸ”¹ ëª¨ë¸ ì •ì˜\n",
    "class ECGSleepCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ECGSleepCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(64 * 960, 256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ğŸ”¹ ë°ì´í„°ë¡œë” ì„¤ì •\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=32)\n",
    "\n",
    "# ğŸ”¹ í•™ìŠµ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ECGSleepCNN(num_classes=4).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ğŸ”¹ í•™ìŠµ ë£¨í”„ \n",
    "for epoch in range(50):  # ìµœëŒ€ 50 epoch\n",
    "    model.train()\n",
    "    loss_sum, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        total += yb.size(0)\n",
    "        correct += (pred == yb).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # ğŸ”¹ ê²€ì¦ ë‹¨ê³„\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            val_total += yb.size(0)\n",
    "            val_correct += (pred == yb).sum().item()\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"ğŸ“˜ Epoch {epoch+1} | Train Loss: {loss_sum:.4f} | Train Acc: {train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test), 32):\n",
    "        xb = X_test[i:i+32].to(device)\n",
    "        yb = y_test[i:i+32].to(device)\n",
    "        outputs = model(xb)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(yb.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['W', 'N12', 'N3', 'R']\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"ğŸ“„ Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
